{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kilos11/Data_Science/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeTPG2dNOk7z"
      },
      "source": [
        "# Review Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fGD9R7AsOk8D"
      },
      "outputs": [],
      "source": [
        "\n",
        "import random  # Import the random module for randomization\n",
        "import json  # Import the json module for handling JSON data\n",
        "import pickle  # Import the pickle module for object serialization\n",
        "from sklearn.model_selection import train_test_split  # Import train_test_split for splitting data\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # Import CountVectorizer and TfidfVectorizer for text feature extraction\n",
        "from sklearn.linear_model import LogisticRegression  # Import LogisticRegression for logistic regression model\n",
        "from sklearn.tree import DecisionTreeClassifier  # Import DecisionTreeClassifier for decision tree model\n",
        "from sklearn.naive_bayes import GaussianNB  # Import GaussianNB for naive Bayes model\n",
        "from sklearn.model_selection import GridSearchCV  # Import GridSearchCV for hyperparameter tuning\n",
        "from sklearn.metrics import f1_score  # Import f1_score for evaluating model performance\n",
        "from sklearn import svm  # Import svm for support vector machine model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KJC7zZkPOk8L"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Sentiment:\n",
        "    NEGATIVE = \"NEGATIVE\"  # Define a constant for negative sentiment\n",
        "    NEUTRAL = \"NEUTRAL\"  # Define a constant for neutral sentiment\n",
        "    POSITIVE = \"POSITIVE\"  # Define a constant for positive sentiment\n",
        "\n",
        "\n",
        "class Review:\n",
        "    def __init__(self, text, score):\n",
        "        self.text = text  # Set the text of the review\n",
        "        self.score = score  # Set the score of the review\n",
        "        self.sentiment = self.get_sentiment()  # Determine the sentiment of the review using the get_sentiment() method\n",
        "\n",
        "    def get_sentiment(self):\n",
        "        if self.score <= 2:\n",
        "            return Sentiment.NEGATIVE  # If the score is less than or equal to 2, the sentiment is negative\n",
        "        elif self.score == 3:\n",
        "            return Sentiment.NEUTRAL  # If the score is 3, the sentiment is neutral\n",
        "        else:\n",
        "            return Sentiment.POSITIVE  # If the score is greater than 3, the sentiment is positive\n",
        "\n",
        "\n",
        "class ReviewContainer:\n",
        "    def __init__(self, reviews):\n",
        "        self.reviews = reviews  # Set the list of reviews in the container\n",
        "\n",
        "    def get_text(self):\n",
        "        return [x.text for x in self.reviews]  # Get the text of each review in a list\n",
        "\n",
        "    def get_sentiment(self):\n",
        "        return [x.sentiment for x in self.reviews]  # Get the sentiment of each review in a list\n",
        "\n",
        "    def evenly_distribute(self):\n",
        "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))  # Filter reviews with negative sentiment\n",
        "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))  # Filter reviews with positive sentiment\n",
        "        positive_shrunk = positive[:len(negative)]  # Shrink the positive review list to match the length of the negative review list\n",
        "        self.reviews = negative + positive_shrunk  # Combine the negative and shrunken positive review lists\n",
        "        random.shuffle(self.reviews)  # Shuffle the reviews randomly\n",
        "\n",
        "'''In this code:\n",
        "\n",
        "- The `Sentiment` class is defined, which contains three constants for representing different sentiment types: `NEGATIVE`, `NEUTRAL`, and `POSITIVE`.\n",
        "- The `Review` class is defined, which represents a single review. It has attributes for the text, score, and sentiment of the review. The `get_sentiment` method is used to determine the sentiment based on the score.\n",
        "- The `ReviewContainer` class is defined, which acts as a container for a collection of reviews. It has methods to retrieve the text and sentiment of the reviews. The `evenly_distribute` method is used to balance the number of positive and negative reviews by shrinking the positive review list and combining it with the negative review list. The resulting list is then shuffled randomly.\n",
        "- The `lambda` function is used with the `filter` function to filter reviews based on their sentiment.'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irIT4exhRY4D",
        "outputId": "c8b3e25d-365a-4875-964e-7b3d56282b7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KxcJo6beOk8Q"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_name = '/content/drive/MyDrive/DS_and_ML_projects-master/Review Sentiment/Books_small_10000.json'\n",
        "\n",
        "reviews = []  # Create an empty list to store the reviews\n",
        "\n",
        "with open(file_name) as f:\n",
        "    for line in f:\n",
        "        review = json.loads(line)  # Parse each line of the file as JSON\n",
        "        reviews.append(Review(review['reviewText'], review['overall']))  # Create a new Review object and append it to the list\n",
        "\n",
        "'''In this code:\n",
        "\n",
        "- The `file_name` variable stores the path to the JSON file containing the reviews.\n",
        "- An empty list, `reviews`, is created to store the `Review` objects.\n",
        "- The `open` function is used to open the file in read mode, and the file object is assigned to `f`.\n",
        "- A loop is used to iterate over each line in the file.\n",
        "- The `json.loads` function is used to parse each line as JSON, converting it into a Python dictionary.\n",
        "- A new `Review` object is created using the values from the parsed JSON (`review['reviewText']` for the text and `review['overall']` for the score).\n",
        "- The newly created `Review` object is appended to the `reviews` list.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNGjtTEZOk8S",
        "outputId": "2f34fa41-7d42-454a-a1b3-88661a3378a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"I'm very happy thus far with this purchase.Have made a total re-do of my eating habits and needed to know some OTHER recipes for the way I want to eat!Kudos for your efforts!Thanks againHAPPY\""
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews[84].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "T_iIwvhWOk8X",
        "outputId": "2bb9d2f2-90ab-4a71-d240-3538be68416f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Warning: Once you begin reading this one you won't want to put it down. Full of excitement and scary events. It sure makes you wonder about some of OUR current government agencies and IF they could be, or have done, anything like this without us ever knowing it was happening. We can only hope the the idiots in charge in DC are on top of things and NOT allowing unfettered activities by ANY of our &#34;security&#34; agencies. We have to hope the &#34;GOOD&#34; guys are in control so nothing like this could happen.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "reviews[74].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "_1t0P1FkOk8Z",
        "outputId": "982fe5f7-09ee-4578-fd02-4a61d993ab51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It was a decent read.. typical story line. Nothing unsavory as so many are. Just a slice of life, plausible.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "reviews[4].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgtzuOKqOk8b"
      },
      "source": [
        "### Prep Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OWBe4HqfOk8d"
      },
      "outputs": [],
      "source": [
        "\n",
        "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
        "\n",
        "# Split the reviews into training and test sets using train_test_split\n",
        "# The 'reviews' list contains the reviews to be split\n",
        "# The 'test_size' parameter specifies the proportion of the data to be allocated for the test set (in this case, 33%)\n",
        "# The 'random_state' parameter sets the random seed for reproducibility\n",
        "\n",
        "train_container = ReviewContainer(training)\n",
        "\n",
        "# Create a ReviewContainer object called 'train_container' using the training set\n",
        "# The 'training' list contains the reviews that will be used for training the model\n",
        "\n",
        "test_container = ReviewContainer(test)\n",
        "\n",
        "# Create a ReviewContainer object called 'test_container' using the test set\n",
        "# The 'test' list contains the reviews that will be used for evaluating the model's performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiASi55vOk8g",
        "outputId": "047e7610-472f-428a-a1c5-52beedaa5b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436\n",
            "436\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_container.evenly_distribute()\n",
        "\n",
        "# Call the 'evenly_distribute' method on 'train_container' to balance the number of positive and negative reviews in the training set\n",
        "# This method shrinks the positive review list to match the length of the negative review list and shuffles the reviews randomly\n",
        "\n",
        "train_x = train_container.get_text()\n",
        "# Get the text of the reviews in the training set using the 'get_text' method of 'train_container'\n",
        "# The 'train_x' variable will contain a list of the review texts\n",
        "\n",
        "train_y = train_container.get_sentiment()\n",
        "# Get the sentiment of the reviews in the training set using the 'get_sentiment' method of 'train_container'\n",
        "# The 'train_y' variable will contain a list of the review sentiments\n",
        "\n",
        "test_container.evenly_distribute()\n",
        "\n",
        "# Call the 'evenly_distribute' method on 'test_container' to balance the number of positive and negative reviews in the test set\n",
        "# This method shrinks the positive review list to match the length of the negative review list and shuffles the reviews randomly\n",
        "\n",
        "test_x = test_container.get_text()\n",
        "# Get the text of the reviews in the test set using the 'get_text' method of 'test_container'\n",
        "# The 'test_x' variable will contain a list of the review texts\n",
        "\n",
        "test_y = test_container.get_sentiment()\n",
        "# Get the sentiment of the reviews in the test set using the 'get_sentiment' method of 'test_container'\n",
        "# The 'test_y' variable will contain a list of the review sentiments\n",
        "\n",
        "print(train_y.count(Sentiment.POSITIVE))\n",
        "# Count the number of positive sentiments in the training set using the 'count' method of the 'train_y' list\n",
        "# Print the result\n",
        "\n",
        "print(train_y.count(Sentiment.NEGATIVE))\n",
        "# Count the number of negative sentiments in the training set using the 'count' method of the 'train_y' list\n",
        "# Print the result\n",
        "\n",
        "'''In this code:\n",
        "\n",
        "- The `evenly_distribute` method is called on both the `train_container` and `test_container` objects to balance the number of positive and negative reviews in each set.\n",
        "- After balancing, the `get_text` method is called on `train_container` and `test_container` to get the text of the reviews in the training and test sets, respectively. The results are stored in `train_x` and `test_x`.\n",
        "- Similarly, the `get_sentiment` method is called on `train_container` and `test_container` to get the sentiment of the reviews in the training and test sets, respectively. The results are stored in `train_y` and `test_y`.\n",
        "- The `count` method is used on `train_y` to count the number of positive and negative sentiments in the training set, and the results are printed.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-5F3T3vOk8j"
      },
      "source": [
        "### Bag of words vectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WuYczXgOk8k",
        "outputId": "f95cb04f-bde4-40b8-e3be-42317c727806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Was not really sure what this book was about.  It was so boring, I stopped reading after the 8th/9th chapter.\n",
            "  (0, 1354)\t0.27267863324867586\n",
            "  (0, 129)\t0.41947771626897\n",
            "  (0, 120)\t0.44496480430090557\n",
            "  (0, 7929)\t0.07514566909764407\n",
            "  (0, 285)\t0.20430064266606754\n",
            "  (0, 6399)\t0.17881355463413195\n",
            "  (0, 7525)\t0.3068496986885096\n",
            "  (0, 1007)\t0.2668721485601011\n",
            "  (0, 7280)\t0.1437670029883238\n",
            "  (0, 4277)\t0.09144528706761185\n",
            "  (0, 149)\t0.1527220495082482\n",
            "  (0, 991)\t0.09235961436579658\n",
            "  (0, 7976)\t0.08426891379599838\n",
            "  (0, 8679)\t0.15740353429718923\n",
            "  (0, 7683)\t0.25824783788042205\n",
            "  (0, 6411)\t0.16720137332287055\n",
            "  (0, 5408)\t0.11614310508129516\n",
            "  (0, 8608)\t0.3256587722422593\n"
          ]
        }
      ],
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Create an instance of the TfidfVectorizer class, which is used to convert text data into numerical features based on term frequency-inverse document frequency (TF-IDF)\n",
        "# Alternatively, you can use CountVectorizer to convert text data into a matrix of token counts\n",
        "\n",
        "vectorizer.fit_transform(train_x)\n",
        "# Fit the vectorizer to the training data (train_x)\n",
        "# This step learns the vocabulary and IDF (inverse document frequency) values from the training data\n",
        "\n",
        "train_x_vectors = vectorizer.fit_transform(train_x)\n",
        "# Convert the text data in the training set (train_x) into a numerical feature matrix using the vectorizer\n",
        "# The resulting train_x_vectors variable will contain the TF-IDF or count vector representation of the text data\n",
        "\n",
        "test_x_vectors = vectorizer.transform(test_x)\n",
        "# Convert the text data in the test set (test_x) into a numerical feature matrix using the vectorizer\n",
        "# The resulting test_x_vectors variable will contain the TF-IDF or count vector representation of the text data\n",
        "\n",
        "print(train_x[0])\n",
        "# Print the first review text in the training set (train_x)\n",
        "\n",
        "print(train_x_vectors[0])\n",
        "# Print the vector representation of the first review text in the training set (train_x_vectors)\n",
        "\n",
        "\n",
        "'''In this code:\n",
        "\n",
        "- The `TfidfVectorizer` class is used to create a vectorizer object that will convert the text data into TF-IDF vectors.\n",
        "- Alternatively, you can use `CountVectorizer` to create a vectorizer object that will convert the text data into a matrix of token counts.\n",
        "- The `fit_transform` method is called on the vectorizer object with `train_x` as input to fit the vectorizer to the training data and convert the training text data into numerical feature vectors.\n",
        "- The resulting `train_x_vectors` variable contains the TF-IDF or count vector representation of the training text data.\n",
        "- The `transform` method is called on the vectorizer object with `test_x` as input to convert the test text data into numerical feature vectors.\n",
        "- The resulting `test_x_vectors` variable contains the TF-IDF or count vector representation of the test text data.\n",
        "- The `print` statements are used to display the first review text in the training set (`train_x[0]`) and its corresponding vector representation (`train_x_vectors[0]`).'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BstUy0ZzOk8n"
      },
      "source": [
        "# Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVGXX7k3Ok8o"
      },
      "source": [
        "### Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6wKlxH7Ok8q",
        "outputId": "0ac1c9b6-8fff-483d-c145-24718692ccc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "clf_svm = svm.SVC(kernel='linear')\n",
        "# Create an instance of the SVM (Support Vector Machine) classifier with a linear kernel\n",
        "# The linear kernel is used as the decision function for classification\n",
        "\n",
        "clf_svm.fit(train_x_vectors, train_y)\n",
        "# Train the SVM classifier using the training data (train_x_vectors) and corresponding labels (train_y)\n",
        "# The classifier learns to classify the text data into positive or negative sentiment based on the feature vectors\n",
        "\n",
        "test_x[0]\n",
        "# Print the first review text in the test set (test_x)\n",
        "\n",
        "clf_svm.predict(test_x_vectors[0])\n",
        "# Use the trained SVM classifier (clf_svm) to predict the sentiment of the first review text in the test set (test_x_vectors[0])\n",
        "# The predict method returns the predicted sentiment label (positive or negative) for the given review text\n",
        "\n",
        "'''In this code:\n",
        "\n",
        "- An instance of the SVM classifier is created using the `svm.SVC` class with a linear kernel specified as `kernel='linear'`.\n",
        "- The `fit` method is called on the SVM classifier to train the model using the training data (`train_x_vectors`) and corresponding labels (`train_y`).\n",
        "- The `test_x[0]` statement prints the first review text in the test set.\n",
        "- The `predict` method is called on the trained SVM classifier (`clf_svm`) with `test_x_vectors[0]` as input to predict the sentiment label (positive or negative) for the first review text in the test set.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XR0CjIayOk8s"
      },
      "source": [
        "#### Decision Tree\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Cv_uymOk8t",
        "outputId": "bfd5ad25-a93d-47d2-dad5-d077f3653981"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "clf_dec = DecisionTreeClassifier()\n",
        "# Create an instance of the DecisionTreeClassifier, which is a decision tree-based classifier\n",
        "\n",
        "clf_dec.fit(train_x_vectors, train_y)\n",
        "# Train the DecisionTreeClassifier using the training data (train_x_vectors) and corresponding labels (train_y)\n",
        "# The classifier learns to classify the text data into positive or negative sentiment based on the feature vectors\n",
        "\n",
        "clf_dec.predict(test_x_vectors[0])\n",
        "# Use the trained DecisionTreeClassifier (clf_dec) to predict the sentiment of the first review text in the test set (test_x_vectors[0])\n",
        "# The predict method returns the predicted sentiment label (positive or negative) for the given review text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6_TzgD9Ok8v"
      },
      "source": [
        "#### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl-ehBB-Ok8w",
        "outputId": "b4a3f753-50ae-4196-e097-854026cf2673"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "\n",
        "clf_gnb = DecisionTreeClassifier()\n",
        "# Create an instance of the DecisionTreeClassifier, a decision tree-based classifier\n",
        "\n",
        "clf_gnb.fit(train_x_vectors, train_y)\n",
        "# Train the DecisionTreeClassifier using the training data (train_x_vectors) and corresponding labels (train_y)\n",
        "# The classifier learns to classify the text data into positive or negative sentiment based on the feature vectors\n",
        "\n",
        "clf_gnb.predict(test_x_vectors[0])\n",
        "# Use the trained DecisionTreeClassifier (clf_gnb) to predict the sentiment of the first review text in the test set (test_x_vectors[0])\n",
        "# The predict method returns the predicted sentiment label (positive or negative) for the given review text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HskHonBLOk8x"
      },
      "source": [
        "#### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWGDhaKNOk8y",
        "outputId": "10d79c6e-fd6f-46d0-ce80-c12839d06139"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "clf_log = LogisticRegression()\n",
        "# Create an instance of the LogisticRegression classifier, which is commonly used for binary classification tasks\n",
        "\n",
        "clf_log.fit(train_x_vectors, train_y)\n",
        "# Train the LogisticRegression classifier using the training data (train_x_vectors) and corresponding labels (train_y)\n",
        "# The classifier learns to classify the text data into positive or negative sentiment based on the feature vectors\n",
        "\n",
        "clf_log.predict(test_x_vectors[0])\n",
        "# Use the trained LogisticRegression classifier (clf_log) to predict the sentiment of the first review text in the test set (test_x_vectors[0])\n",
        "# The predict method returns the predicted sentiment label (positive or negative) for the given review text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpylB3elOk80"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i74Bd1PwOk80",
        "outputId": "706f74da-5fae-4419-81b8-061d4c8b7a1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8076923076923077\n",
            "0.6610576923076923\n",
            "0.6658653846153846\n",
            "0.8052884615384616\n"
          ]
        }
      ],
      "source": [
        "print(clf_svm.score(test_x_vectors, test_y))\n",
        "print(clf_dec.score(test_x_vectors, test_y))\n",
        "print(clf_gnb.score(test_x_vectors, test_y))\n",
        "print(clf_log.score(test_x_vectors, test_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUqz_snhOk82",
        "outputId": "4bd6e7e9-76b5-4040-8d59-4780508fcf83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.80582524, 0.80952381])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztpaUK7aOk83",
        "outputId": "9f5762d9-5090-4f84-fa2a-2f435abb0bb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "208"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "test_y.count(Sentiment.POSITIVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYUZTTt9Ok84",
        "outputId": "3ff1c627-eb5d-4840-fd87-2aa2cdfc4dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE', 'NEGATIVE', 'POSITIVE'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_set = ['did not enjoy', 'bad book, do not buy', 'good']\n",
        "new_test = vectorizer.transform(test_set)\n",
        "\n",
        "clf_svm.predict(new_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_foTtIUOk86"
      },
      "source": [
        "## Tuning model with Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "An1JWgAVOk86",
        "outputId": "71a3a707-5b05-4ce7-dc6f-e2a656985b15"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=SVC(),\n",
              "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
              "             param_grid={&#x27;C&#x27;: (1, 4, 8, 16, 32), &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;rbf&#x27;)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
              "             param_grid={&#x27;C&#x27;: (1, 4, 8, 16, 32), &#x27;kernel&#x27;: (&#x27;linear&#x27;, &#x27;rbf&#x27;)})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "parameters = {'kernel': ('linear', 'rbf'), 'C': (1, 4, 8, 16, 32)}\n",
        "# Define a dictionary of parameters for the SVM classifier\n",
        "# The 'kernel' parameter specifies the type of kernel to be used (linear or radial basis function)\n",
        "# The 'C' parameter controls the regularization strength\n",
        "\n",
        "svc = svm.SVC()\n",
        "# Create an instance of the SVM classifier\n",
        "\n",
        "clf = GridSearchCV(svc, parameters, cv=5)\n",
        "# Create an instance of the GridSearchCV class, which performs an exhaustive search over specified parameter values for an estimator\n",
        "# In this case, it searches for the best combination of 'kernel' and 'C' values for the SVM classifier\n",
        "# The 'cv' parameter specifies the number of folds for cross-validation\n",
        "\n",
        "clf.fit(train_x_vectors, train_y)\n",
        "# Fit the GridSearchCV object to the training data (train_x_vectors) and corresponding labels (train_y)\n",
        "# It performs the grid search to find the best combination of parameters\n",
        "# The classifier learns to classify the text data into positive or negative sentiment based on the feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYkxCs53Ok88",
        "outputId": "029084bb-d81b-4d9a-9210-5680651715db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8197115384615384\n"
          ]
        }
      ],
      "source": [
        "print(clf.score(test_x_vectors, test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4WIRJq5Ok89"
      },
      "source": [
        "## Saving Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DQUTJX5mOk8-"
      },
      "outputs": [],
      "source": [
        "with open('sentiment_classifier.pkl', 'wb') as f:\n",
        "    pickle.dump(clf, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuyGfEA5Ok8_"
      },
      "source": [
        "## Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "l1Pj8q6ZOk9A"
      },
      "outputs": [],
      "source": [
        "with open('sentiment_classifier.pkl', 'rb') as f:\n",
        "    loaded_clf = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKTwmVcdOk9B",
        "outputId": "2cc05ce3-0f6a-47c8-82ca-46c1dcc127be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thank goodness I found this after all books were published. I would've gone crazy waiting. 6 books. Super quick read - enjoyed immensely!!Here's the premise...Girl meets boy, boy is f'd up, get the picture?  BUT it's so much more than that. It's smart, witty, sexy, sad, and hopeful. Will the girl get her man or vice versa?  Read it!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NEGATIVE'], dtype='<U8')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "print(test_x[84])\n",
        "\n",
        "loaded_clf.predict(test_x_vectors[0])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}